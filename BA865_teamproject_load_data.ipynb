{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_EOqza17-Ey",
        "outputId": "dff2d204-4e51-414a-af08-12d768358476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "nmluEc1aWVYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 3 : print loading process"
      ],
      "metadata": {
        "id": "fEzRl2YdZclT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from natsort import natsorted\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import time\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "# train_folder_path = \"/content/gdrive/MyDrive/BA865/data/train_(test_model)\"\n",
        "# test_folder_path = \"/content/gdrive/MyDrive/BA865/data/test_(test_model)\"\n",
        "train_folder_path = \"/content/gdrive/MyDrive/BA865/data/train_frame_50\"\n",
        "test_folder_path = \"/content/gdrive/MyDrive/BA865/data/test_frame_50\"\n",
        "train_label_path = '/content/gdrive/MyDrive/BA865/data/train.csv'\n",
        "test_label_path = '/content/gdrive/MyDrive/BA865/data/test.csv'\n",
        "\n",
        "def load_images(folder_path):\n",
        "    images, filenames, new_filenames = [], [], []\n",
        "    start_time = time.time() # Start time\n",
        "    # Iterate through filenames in sorted order\n",
        "    for i, filename in enumerate(natsorted(os.listdir(folder_path))):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            img = Image.open(os.path.join(folder_path, filename)).resize((224, 224))\n",
        "            img_array = np.array(img) / 255.0 # Normalization\n",
        "            images.append(img_array)\n",
        "            filenames.append(filename)\n",
        "            new_filenames.append(filename.split(\"-\")[0] + \".avi\") # Modify the file name\n",
        "            if (i + 1) % 500 == 0:\n",
        "                print(f\"{i + 1} images loaded...\")\n",
        "                duration = time.time() - start_time # Duration\n",
        "                print(f\"It took {duration:.2f} seconds.\")\n",
        "    return np.array(images), pd.DataFrame({\"Original Filename\": filenames, \"New Filename\": new_filenames})\n",
        "\n",
        "\n",
        "def load_data_and_labels(folder_path, label_path):\n",
        "    start_time = time.time() # Start timce\n",
        "    # Call the above function to load images and create a DataFrame with filenames\n",
        "    image, df_filenames = load_images(folder_path)\n",
        "    # Read label file (train / test)\n",
        "    labels = pd.read_csv(label_path)\n",
        "    # Merge the label\n",
        "    df_filenames = pd.merge(df_filenames, labels[['Name', 'Label']], left_on='New Filename', right_on='Name')\n",
        "    # Encode the labels using LabelEncoder and extract the label vector\n",
        "    label = LabelEncoder().fit_transform(df_filenames['Label'])\n",
        "    df_filenames['label_encode'] = label\n",
        "    end_time = time.time() # End time\n",
        "    duration = end_time - start_time # Duration\n",
        "    print(f\"Loading data and labels took {duration:.2f} seconds.\")\n",
        "    return image, label, df_filenames\n",
        "\n",
        "# Load training and test data\n",
        "X_train, y_train, df_train_filenames = load_data_and_labels(folder_path = train_folder_path,label_path = train_label_path)\n",
        "X_test, y_test, df_test_filenames = load_data_and_labels(folder_path = test_folder_path, label_path = test_label_path)\n",
        "# Drop the duplicate column\n",
        "df_test_filenames.drop(columns = 'label_encode', inplace = True)\n",
        "df_test_filenames = pd.merge(df_test_filenames, df_train_filenames[['Label', 'label_encode']], on='Label', how='left')\n",
        "df_test_filenames = df_test_filenames.drop_duplicates()\n",
        "y_test = df_test_filenames['label_encode'].values\n",
        "\n",
        "# Define CNN model\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train / Validation Split\n",
        "model.fit(X_train, y_train, epochs=1, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy[1] * 100 , \"%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "d4sZ1ZNhZYWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 2 : With test"
      ],
      "metadata": {
        "id": "3v0OWZ4aqI1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from natsort import natsorted\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "# train_folder_path = \"/content/gdrive/MyDrive/BA865/data/train_(test_model)\"\n",
        "# test_folder_path = \"/content/gdrive/MyDrive/BA865/data/test_(test_model)\"\n",
        "train_folder_path = \"/content/gdrive/MyDrive/BA865/data/train_frame_50\"\n",
        "test_folder_path = \"/content/gdrive/MyDrive/BA865/data/test_frame_50\"\n",
        "train_label_path = '/content/gdrive/MyDrive/BA865/data/train.csv'\n",
        "test_label_path = '/content/gdrive/MyDrive/BA865/data/test.csv'\n",
        "\n",
        "def load_images(folder_path):\n",
        "    images, filenames, new_filenames = [], [], []\n",
        "    # Iterate through filenames in sorted order\n",
        "    for filename in natsorted(os.listdir(folder_path)):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            img = Image.open(os.path.join(folder_path, filename)).resize((224, 224))\n",
        "            img_array = np.array(img) / 255.0 # Normalization\n",
        "            images.append(img_array)\n",
        "            filenames.append(filename)\n",
        "            new_filenames.append(filename.split(\"-\")[0] + \".avi\") # Modify the file name\n",
        "    return np.array(images), pd.DataFrame({\"Original Filename\": filenames, \"New Filename\": new_filenames})\n",
        "\n",
        "def load_data_and_labels(folder_path, label_path):\n",
        "    # Call the above function to load images and create a DataFrame with filenames\n",
        "    image, df_filenames = load_images(folder_path)\n",
        "    # Read label file (train / test)\n",
        "    labels = pd.read_csv(label_path)\n",
        "    # Merge the label\n",
        "    df_filenames = pd.merge(df_filenames, labels[['Name', 'Label']], left_on='New Filename', right_on='Name')\n",
        "    # Encode the labels using LabelEncoder and extract the label vector\n",
        "    label = LabelEncoder().fit_transform(df_filenames['Label'])\n",
        "    df_filenames['label_encode'] = label\n",
        "    return image, label, df_filenames\n",
        "\n",
        "# Load training and test data\n",
        "X_train, y_train, df_train_filenames = load_data_and_labels(folder_path = train_folder_path,label_path = train_label_path)\n",
        "X_test, y_test, df_test_filenames = load_data_and_labels(folder_path = test_folder_path, label_path = test_label_path)\n",
        "# Drop the duplicate column\n",
        "df_test_filenames.drop(columns = 'label_encode', inplace = True)\n",
        "df_test_filenames = pd.merge(df_test_filenames, df_train_filenames[['Label', 'label_encode']], on='Label', how='left')\n",
        "df_test_filenames = df_test_filenames.drop_duplicates()\n",
        "y_test = df_test_filenames['label_encode'].values\n",
        "\n",
        "# Define CNN model\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train / Validation Split\n",
        "model.fit(X_train, y_train, epochs=1, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy[1] * 100 , \"%\")\n"
      ],
      "metadata": {
        "id": "_t6mPRyXk24Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Version 1 : without x_test , y_test"
      ],
      "metadata": {
        "id": "wg3wyGYcklH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from natsort import natsorted\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "folder_path = \"/content/gdrive/MyDrive/BA865/data/train_(test_model)\"\n",
        "test_folder_path = \"/content/gdrive/MyDrive/BA865/data/train_frame\"\n",
        "\n",
        "def load_images(folder_path):\n",
        "    images, filenames, new_filenames = [], [], []\n",
        "    for filename in natsorted(os.listdir(folder_path)):\n",
        "        if filename.endswith(\".jpg\"):\n",
        "            img = Image.open(os.path.join(folder_path, filename)).resize((224, 224))\n",
        "            img_array = np.array(img) / 255.0 # Normalization\n",
        "            images.append(img_array)\n",
        "            filenames.append(filename)\n",
        "            new_filenames.append(filename.split(\"-\")[0] + \".avi\")\n",
        "    return np.array(images), pd.DataFrame({\"Original Filename\": filenames, \"New Filename\": new_filenames})\n",
        "\n",
        "# Return Images & Dataframe with original and ne filename\n",
        "X_train, df_filenames = load_images(folder_path)\n",
        "\n",
        "# Get labels\n",
        "Label = pd.read_csv('/content/gdrive/MyDrive/BA865/data/train.csv')\n",
        "df_filenames = pd.merge(df_filenames, Label[['Name', 'Label']], left_on='New Filename', right_on='Name')\n",
        "y_train = df_filenames['Label']\n",
        "\n",
        "# Define CNN model\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Transform y_label from string to float\n",
        "y_train = LabelEncoder().fit_transform(y_train)\n",
        "\n",
        "# Train / Test Split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "id": "kdXYiFbsYSGw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}